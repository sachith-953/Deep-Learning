{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chFxLC6rxIuW"
      },
      "outputs": [],
      "source": [
        "#Import all the libraries needed\n",
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDa_MsDyx_Jc"
      },
      "outputs": [],
      "source": [
        "#Preview dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSRVxC5JxIuY",
        "outputId": "54150b08-2054-49e7-e94c-a8b834fc54ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = pathlib.Path('/content/drive/My Drive/SC549Data/IMDB Dataset.csv')\n",
        "data = pd.read_csv(data_dir)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh5243vMyKhs"
      },
      "outputs": [],
      "source": [
        "#Declaring the english stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzux8uRZxIuZ",
        "outputId": "42d8e8a3-27ed-49c6-87fc-d0177d34da24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "english_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA4BqsNlySGl"
      },
      "outputs": [],
      "source": [
        "#Preprocessing and Encoding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL16UfD6xIua",
        "outputId": "195c5810-128e-4abd-b260-de717d32773d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def load_dataset():\n",
        "    x_data = data['review']       # Reviews/Input\n",
        "    y_data = data['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "\n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cf37dMjxIub",
        "outputId": "42ab8b19-f085-4bd2-9a67-e8d07c930091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Set\n",
            "27458    [i, bore, story, plot, lines, presented, many,...\n",
            "44676    [i, plagued, nightmares, involving, sesame, st...\n",
            "5615     [this, one, worst, movies, i, ever, seen, than...\n",
            "32856    [to, put, simply, i, enjoyed, film, the, reaso...\n",
            "2955     [ring, ring, have, horror, directors, hotline,...\n",
            "                               ...                        \n",
            "13545    [i, expected, fame, uplifting, film, ended, op...\n",
            "17546    [carmen, one, best, films, i, ever, seen, it, ...\n",
            "10016    [a, really, bad, movie, good, moments, qualiti...\n",
            "48218    [suzumiya, haruhi, utsu, the, melancholy, haru...\n",
            "32109    [this, movie, perfect, portrayal, the, nutcrac...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "40354    [anyone, enjoys, lynchian, weirdness, twin, pe...\n",
            "19450    [hollow, point, alright, movie, worth, half, p...\n",
            "43340    [an, absorbing, exploration, virtual, reality,...\n",
            "47245    [this, cool, marvel, superhero, game, pays, pr...\n",
            "26599    [i, seen, mst, k, version, uncut, version, i, ...\n",
            "                               ...                        \n",
            "47318    [bon, voyage, fun, audience, combines, requisi...\n",
            "49023    [being, huge, fan, bottom, series, really, loo...\n",
            "34095    [the, romance, movie, also, main, theme, good,...\n",
            "8759     [spoilers, below, night, mother, story, jesse,...\n",
            "42136    [l, humanit, murder, mystery, these, movies, t...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "27458    1\n",
            "44676    1\n",
            "5615     0\n",
            "32856    1\n",
            "2955     0\n",
            "        ..\n",
            "13545    1\n",
            "17546    1\n",
            "10016    0\n",
            "48218    1\n",
            "32109    1\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "40354    1\n",
            "19450    0\n",
            "43340    1\n",
            "47245    1\n",
            "26599    0\n",
            "        ..\n",
            "47318    1\n",
            "49023    0\n",
            "34095    1\n",
            "8759     0\n",
            "42136    0\n",
            "Name: sentiment, Length: 10000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#train to test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaz82yjyykT1"
      },
      "outputs": [],
      "source": [
        "#Function for getting the maximum review length, by calculating the mean of all the reviews length (using numpy.mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-5QgyYgxIuc"
      },
      "outputs": [],
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASGim_ImyrZk"
      },
      "outputs": [],
      "source": [
        "#Tokenize and Pad/Truncate Reviews\n",
        "#post, pad or truncate the words in the back of a sentence\n",
        "#pre, pad or truncate the words in front of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3dXUq6QxIuc",
        "outputId": "e51865f4-fe37-438c-a841-1ed7be4b51a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[    1  2611    13 ...  6668    11   513]\n",
            " [    1  8029  4004 ...     0     0     0]\n",
            " [    8     5   153 ...  6327  6238   905]\n",
            " ...\n",
            " [   39    15    20 ...   156    20  2308]\n",
            " [14720  9936 92224 ...   487   732   887]\n",
            " [    8     3   302 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[  154  4333 17927 ...     0     0     0]\n",
            " [ 4145   127  2537 ...     0     0     0]\n",
            " [  699  6717  4899 ...   637   361  3709]\n",
            " ...\n",
            " [    2   748     3 ...     0     0     0]\n",
            " [  989  9054   219 ...    28   285  1837]\n",
            " [ 1196   515   716 ...  1550  3905  5376]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ],
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGmkzZzryxRz"
      },
      "outputs": [],
      "source": [
        "#Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKsE4CzxxIuc",
        "outputId": "6949418f-0ee2-4a29-e8c1-afc04675be15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 130, 32)           2951424   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                24832     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2976321 (11.35 MB)\n",
            "Trainable params: 2976321 (11.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaEkDqp0y3s8"
      },
      "outputs": [],
      "source": [
        "#Set hyperparameters\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfXVls9hzBrk"
      },
      "outputs": [],
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncwxJzJ4xIud"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY6F99qYRorZ"
      },
      "outputs": [],
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_DGv7xXxIud",
        "outputId": "b369b00f-7a99-4c48-edd1-49098764aff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.7479\n",
            "Epoch 1: accuracy improved from -inf to 0.74785, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 84s 260ms/step - loss: 0.4695 - accuracy: 0.7479\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9236\n",
            "Epoch 2: accuracy improved from 0.74785 to 0.92360, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 80s 254ms/step - loss: 0.2122 - accuracy: 0.9236\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9607\n",
            "Epoch 3: accuracy improved from 0.92360 to 0.96070, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 86s 276ms/step - loss: 0.1239 - accuracy: 0.9607\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9772\n",
            "Epoch 4: accuracy improved from 0.96070 to 0.97725, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 82s 262ms/step - loss: 0.0813 - accuracy: 0.9772\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9845\n",
            "Epoch 5: accuracy improved from 0.97725 to 0.98453, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 84s 268ms/step - loss: 0.0582 - accuracy: 0.9845\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5da478dde0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqUvLFwhzGYk"
      },
      "outputs": [],
      "source": [
        "#Model testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cIDxgtxxIud",
        "outputId": "d3479d35-0c5b-4cf2-c3f0-22473caf5727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 9s 27ms/step\n",
            "Correct Prediction: 8730\n",
            "Wrong Prediction: 1270\n",
            "Accuracy: 87.3\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(x=x_test)\n",
        "y_pred = (pred >= 0.5) * 1\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvWhkDfXxIug"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
